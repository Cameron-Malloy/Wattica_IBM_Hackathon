#!/usr/bin/env python3
"""
Data cleaning and vulnerability scoring functions for the AccessMap Equity Agent System.
"""

import pandas as pd
import numpy as np
import logging

logger = logging.getLogger(__name__)

def sample_cities(df, sample_size=200, random_state=42):
    """
    Take a random sample of cities to reduce processing time.
    
    Args:
        df (pd.DataFrame): Full census data
        sample_size (int): Number of cities to sample (default: 200)
        random_state (int): Random seed for reproducibility
        
    Returns:
        pd.DataFrame: Sampled data
    """
    logger.info(f"Sampling {sample_size} cities from {len(df)} total cities...")
    
    # Ensure we don't sample more than we have
    actual_sample_size = min(sample_size, len(df))
    
    # Take stratified sample to maintain diversity
    # Sample from each priority level proportionally
    df_sampled = df.sample(n=actual_sample_size, random_state=random_state, replace=False)
    
    logger.info(f"âœ… Sampled {len(df_sampled)} cities for analysis")
    return df_sampled

def clean_data(df):
    """
    Clean the census data by handling missing values and outliers.
    
    Args:
        df (pd.DataFrame): Raw census data
        
    Returns:
        pd.DataFrame: Cleaned data
    """
    logger.info("Cleaning census data...")
    
    # Make a copy to avoid modifying original
    df_clean = df.copy()
    
    # Handle missing values
    df_clean = df_clean.dropna(subset=['percent_over_65', 'median_income', 'percent_disabled'])
    
    # Remove outliers for income (keep reasonable range)
    df_clean = df_clean[df_clean['median_income'] > 0]
    df_clean = df_clean[df_clean['median_income'] < 1000000]
    
    # Remove outliers for percentages (keep 0-100%)
    df_clean = df_clean[df_clean['percent_over_65'] >= 0]
    df_clean = df_clean[df_clean['percent_over_65'] <= 1]
    df_clean = df_clean[df_clean['percent_disabled'] >= 0]
    df_clean = df_clean[df_clean['percent_disabled'] <= 1]
    
    logger.info(f"Cleaned data: {len(df_clean)} places remaining")
    return df_clean

def add_vulnerability_score(df):
    """
    Add vulnerability scores based on demographic factors.
    
    Args:
        df (pd.DataFrame): Cleaned census data
        
    Returns:
        pd.DataFrame: Data with vulnerability scores
    """
    logger.info("Adding vulnerability scores...")
    
    df_scored = df.copy()
    
    # Calculate individual factor scores (0-100 scale)
    # Higher scores = higher vulnerability
    
    # Elderly score (0-100)
    df_scored['elderly_score'] = (df_scored['percent_over_65'] * 100).round(2)
    
    # Disability score (0-100)
    df_scored['disabled_score'] = (df_scored['percent_disabled'] * 100).round(2)
    
    # Income score (0-100) - lower income = higher vulnerability
    # Normalize income to 0-100 scale (inverse relationship)
    max_income = df_scored['median_income'].max()
    min_income = df_scored['median_income'].min()
    df_scored['income_score'] = ((max_income - df_scored['median_income']) / (max_income - min_income) * 100).round(2)
    
    # Overall vulnerability score (weighted average)
    # Weights: Elderly (40%), Disability (35%), Income (25%)
    df_scored['vulnerability_score'] = (
        df_scored['elderly_score'] * 0.4 +
        df_scored['disabled_score'] * 0.35 +
        df_scored['income_score'] * 0.25
    ).round(2)
    
    logger.info("Vulnerability scores added successfully")
    return df_scored

def prepare_data_for_agents(df):
    """
    Prepare the data for agent analysis by adding priority levels and categories.
    
    Args:
        df (pd.DataFrame): Data with vulnerability scores
        
    Returns:
        pd.DataFrame: Data ready for agent analysis
    """
    logger.info("Preparing data for agents...")
    
    df_agent_ready = df.copy()
    
    # Add priority levels based on vulnerability score
    df_agent_ready['priority_level'] = pd.cut(
        df_agent_ready['vulnerability_score'],
        bins=[0, 30, 60, 100],
        labels=['Low', 'Medium', 'High'],
        include_lowest=True
    )
    
    # Add population categories
    df_agent_ready['population_category'] = pd.cut(
        df_agent_ready['percent_over_65'],
        bins=[0, 0.1, 0.2, 1.0],
        labels=['Low Elderly', 'Medium Elderly', 'High Elderly'],
        include_lowest=True
    )
    
    # Add disability categories
    df_agent_ready['disability_category'] = pd.cut(
        df_agent_ready['percent_disabled'],
        bins=[0, 0.1, 0.2, 1.0],
        labels=['Low Disability', 'Medium Disability', 'High Disability'],
        include_lowest=True
    )
    
    # Add income categories
    df_agent_ready['income_category'] = pd.cut(
        df_agent_ready['median_income'],
        bins=[0, 50000, 100000, 1000000],
        labels=['Low Income', 'Medium Income', 'High Income'],
        include_lowest=True
    )
    
    logger.info("Data prepared for agents successfully")
    return df_agent_ready
